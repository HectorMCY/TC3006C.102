\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Inteligencia Artifical Avansada para la Ciencia de Datos I}
\author{Álvaro Morán Errejón 		     | A01638034\\Héctor Manuel Cárdenas Yáñez	 | A01634615\\Isaí Ambrocio				     | A01625101\\Siddhartha López Valenzuela      | A00227694}


\date{September 4th, 2023}

\usepackage{natbib}
\usepackage{graphicx}

\begin{document}

\maketitle

\section{Introduction}
This report intends to show a solution the problem of "Activivty Recognition in Senior Citizens". 
The Human Activity Recognition 70+ (HAR70+) dataset is a professionally-annotated dataset containing 18 fit-to-frail older-adult
 subjects (70-95 years old) wearing two 3-axial accelerometers for around 40 minutes during a semi-structured free-living protocol.
  The sensors were attached to the right thigh and lower back
Each subject's recordings are provided in a separate .csv file. The purpose was to train machine learning models for human activity 
recognition on professionally-annotated accelerometer data of fit-to-frail older adults. El equipo, al estar comprometido con la ética
 al momento de trabajar, hace mención que los conjuntos de datos utilizados para hacer las pruebas, modelaciones y llevar al cabo la
  práctica, fueron tomados de la plataforma Kaggle en el siguiente hipervínculo:
   https://www.kaggle.com/datasets/anshtanwar/adult-subjects-70-95-years-activity-recognition \\ \\
El propietario al subir los datos a la plataforma permite que los datos sean utilizados de forma libre de acuerdo a la licencia
 “Attribution 4.0 International (CC BY 4.0)”, la cual es estipulada en la misma. Agradecemos a ANSH TANWAR quien es el propietario
  que compartió los conjuntos de datos, como descripciones de los mismos.


\section{Data Analysis}
    \subsection{Loading Data}

    For staters, all the data was uploaded to Google Colab and was roughly concatenated into a huge DataFrame containing 
    all the information so that it could be used for further analysis. \pagebreak
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/intro1.png}
        \label{fig:intro1}
    \end{figure}




    \subsection{Exploratory Analysis}

    As you can see below we stated by simply undestanding the size of the sample, then print a summary of the data 
    in a table and understanding the type of data in three: object, float and integer. \pagebreak
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/intro2.png}
        \label{fig:intro2}
    \end{figure}




    As we can see there is no missng information in any of the columns, which in turn will save us a step for creating the model. 
    There we can also see that by uiing the function .unique() we are able to see the labels, which coincide with thoseis Kaggle. 
    It is divided as follows \\ \\
    1. walking \newline
    3. shuffling\newline
    4. ascending stairs\newline
    5. descending stairs \newline
    6. standing \newline
    7. sitting \newline
    8. lying \pagebreak
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/intro3.png}
        \label{fig:intro3}
    \end{figure}






    It is also important to highlight that we manage to understand how the data is distributed within each label. 
    As we can see, the data is unfairly distributed among the lables. Therefore we must implement a balancing method in order 
    to advance with the perdiction method. Balancing data is crucial to prevent biased models, enhance generalization, ensure 
    fairness and equity and, most importantly improve the performance metrics of the method. By addressing data imbalances we are
    making the model more accurate and equitable predictions, essentialy making it more reliable and useful in real-world applications 
    while mitigating the negatve impact of class imbalances. \pagebreak
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/intro4.png}
        \label{fig:intro4}
    \end{figure}





    Next we analized how the variables function in regard with the tieme. The code below graphs the data in labels 
    and shows how is acts as the time goes by. It is worth noting that this is merely a small sample of the Data Frame, 
    since running this code with the whole amount of data would take too long to display. However, we areable to see the 
    how each individual label acts in comparison to the rest. The amouont of time and movemente clearly displays the 
    relevance of some labels over others. Image:\pagebreak
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/intro5.png}
        \label{fig:intro5}
    \end{figure}

    Image:\pagebreak

    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/intro6.png}
        \label{fig:intro6}
    \end{figure}

    

    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/intro7.png}
        \label{fig:intro7}
    \end{figure}

    Image:\pagebreak

    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/intro8.png}
        \label{fig:intro8}
    \end{figure}

    

    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/intro9.png}
        \label{fig:intro9}
    \end{figure}

    Image:\pagebreak

    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/intro10.png}
        \label{fig:intro10}
    \end{figure}


    Finally, we performed a Data Clusering in order to further understand how the data works.
    As we can see the data is very close together, mostly divided in three mayor labels, just as we saw prevosly, 
    however, it is worth noting the the data is closely tied together, there aren't any particular outliers that we need 
    to take into consideration.
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/intro11.png}
        \label{fig:intro11}
    \end{figure}

    Image:\pagebreak

    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/intro12.png}
        \label{fig:intro12}
    \end{figure}

\section{Data Processing}
    \subsection{Unbalanced Analysis}

    First, we start by analyzing the model as it is,  with the data unbalanced. 
    The following code starts by setting up a stratified k-fold cross-validation, splitting the dataset into three folds 
    and shuffling the data. It employs a linear Support Vector Classifier (SVC) for training and prediction. During each fold, 
    it trains the model on a training subset and evaluates its performance on a validation subset, storing the true and 
    predicted labels. After the cross-validation, it concatenates the true and predicted labels from all folds and generates 
    a comprehensive classification report, presenting key classification metrics such as precision, recall, f1-score, and support 
    for each class. This report provides a consolidated view of the model's performance across all folds, offering insights into 
    its generalization capabilities and predictive accuracy on the given dataset. \pagebreak
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/ua1.png}
        \label{fig:ua1}
    \end{figure}
    
    As we can see by the results, the model as it is, with unbalanced data,  returns a poorly trained model. 
    The precision for two labels is approximately 98 percent, which is very good. However, the model is deficient in 
    predicting a precise answer for the remaining labels. Some even have 0 percent precision. This highlights the importance of creating 
    a balancing method in order to create an optimized and accurate model. \pagebreak
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/ua2.png}
        \label{fig:ua2}
    \end{figure}


    \subsection{Balancing Methods}

    The following code begins by randomly sampling 10 percent of the rows from an original dataset and segregates 
    features and labels accordingly. It then focuses on addressing class imbalance in a classification task. The first approach, 
    "Upsampling," involves resampling the minority classes to equal the majority class in terms of sample count. The code accomplishes 
    this by duplicating samples from the minority class, achieving a more balanced dataset. The second strategy involves 
    utilizing a weighted loss function in conjunction with the Support Vector Classifier (SVC). By setting the class weights 
    to 'balanced,' the algorithm automatically adjusts these weights based on the class distribution in the training data, 
    effectively mitigating the imbalanced class issue. Both strategies aim to improve classification performance by enhancing 
    the model's ability to handle disparate class frequencies. The code concludes by presenting a detailed classification report, 
    offering insights into the model's performance across various evaluation metrics.\pagebreak
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.5]{/Users/manuelcardenas/Desktop/Latex/AI/images/bm1.png}
        \label{fig:bm1}
    \end{figure}

    The result displays that although the methods did show some progress and optimized the unbalane defficiency, 
    it's still not the best solution for dealing the problem. The precision stil wrong, having some labels with 0 precision. \pagebreak
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/bm2.png}
        \label{fig:bm2}
    \end{figure}

    \subsection{Methods}

    The next code conducts a comprehensive evaluation of multiple machine learning classifiers 
    (linear SVM, RBF SVM, KNN, Decision Tree, Linear Discriminant Analysis, Random Forest, Gradient Boosting, and Polynomial SVM) 
    on the dataset. The dataset is initially sampled, and features and labels are extracted. Each classifier is trained and evaluated 
    using 3-fold cross-validation. The evaluation involves training on a subset of the data and testing on another, followed by 
    generating a classification report detailing precision, recall, F1-score, and support metrics for each class. The main goal is 
    to assess and compare the performance of these classifiers on the dataset.\pagebreak

    Linear SVM
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/m1.png}
        \label{fig:m1}
    \end{figure}

    RBF SVM \pagebreak
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/m2.png}
        \label{fig:m2}
    \end{figure}

    KNN
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/m3.png}
        \label{fig:m3}
    \end{figure}

    Decision Tree\pagebreak
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/m4.png}
        \label{fig:m4}
    \end{figure}

    Linear Discriminant Analysis
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/m5.png}
        \label{fig:m5}
    \end{figure}

    Random Forest\pagebreak
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/m6.png}
        \label{fig:m6}
    \end{figure}

    Gradient Boosting
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/m7.png}
        \label{fig:m7}
    \end{figure}

    SVM with Kernel Polynomial\pagebreak
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/m8.png}
        \label{fig:m8}
    \end{figure}

    The result display that the best model is the Random Forest. It shows the best precision overall in all the labels.
     The worst being of 0.53 and the best of 1.00. However, the recall is still pretty deficient on labels: 3, 4, and 5. \pagebreak
     Linear SVM
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/r1.png}
        \label{fig:r1}
    \end{figure}
    - \pagebreak

    RBF-SVM and KNN
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/r2.png}
        \label{fig:r2}
    \end{figure}
    - \pagebreak

    Decision Tree and Linear Discriminant
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/r3.png}
        \label{fig:r3}
    \end{figure}
    - \pagebreak

    Random Forest and Gradient Boosting
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/r4.png}
        \label{fig:r4}
    \end{figure}
    - \pagebreak

    Polynomial SVM
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/r5.png}
        \label{fig:r5}
    \end{figure}

    \subsection{Random Forest and Balanced Random Forest Model}

    Considering the results of all the models, we decided to use two: Random Forest, which gave us the best precisión, 
    and Balanced Random Forest, which displayed the highest recall from all the models. The code focuses on classification 
    using these two methods. It begins by sampling the dataset and extracting features and labels. It then trains and evaluates 
    a Random Forest classifier and a Balanced Random Forest classifier using 3-fold stratified cross-validation, presenting 
    classification reports for both. Afterwards, it creates an ensemble using a Voting Classifier that combines both classifiers 
    and evaluates the ensemble's performance using the same cross-validation approach, generating a classification report. 
    The goal is to compare the individual and combined performances of Random Forest and Balanced Random Forest, exploring 
    the potential benefits of an ensemble approach for classification tasks.\pagebreak
    Random Forest
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/rf1.png}
        \label{fig:rf1}
    \end{figure}
    - \pagebreak

    Balanced Random Forest
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/rf2.png}
        \label{fig:rf2}
    \end{figure}
    - \pagebreak

    Ensemble both classifiers
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/rf3.png}
        \label{fig:rf3}
    \end{figure}
    
    As we can see both methods individually have great results for precision and recall respectively. 
    By ensembling a method with both we get a new method in the middle. It doesn't have the precision from the Random Forest nor the recall of the Balanced Random Forest, instead it has an in between.\pagebreak

    Random Forest and Balanced Random Forest Results
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/rf4.png}
        \label{fig:rf4}
    \end{figure}
    - \pagebreak

    Random Forest + Balanced Random Forest Results
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/rf5.png}
        \label{fig:rf5}
    \end{figure}

    \subsection{Optimal Selection of Hyperparameters}

    Next, we decided to search for the optimal number of hyperparameters. The following code conducts a comprehensive 
    evaluation of the same machine learning classifiers (Random Forest, Balanced Random Forest, and an ensemble of both using 
    a Voting Classifier) just as before. Then the hyperparameters are optimized through randomized search. The ensemble is evaluated 
    using the best hyperparameters and another classification report is generated. This process enables a thorough assessment 
    of individual classifiers and an ensemble, demonstrating how hyperparameter tuning can enhance the performance of an ensemble 
    combining diverse classifiers.\pagebreak
    Random Forest
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/h1.png}
        \label{fig:h1}
    \end{figure}
    - \pagebreak

    Balanced Random Forest
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/h2.png}
        \label{fig:h2}
    \end{figure}
    - \pagebreak

    Hyperparameters part 1
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/h3.png}
        \label{fig:h3}
    \end{figure}
    - \pagebreak

    Hyperparameters part 2
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/h4.png}
        \label{fig:h4}
    \end{figure}
    
    By getting the optimal number of hyperparameter we can now test the model and models results for precision,  recall and f1 \pagebreak

    Random Forest and Balanced Random Forest Results
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/h5.png}
        \label{fig:h5}
    \end{figure}
    - \pagebreak

    Hyperparameters
    \begin{figure}[h]
        \centering
        \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/h6.png}
        \label{fig:h6}
    \end{figure}

    \subsection{Model tuning with hyperparameters}

    Lastly, we adjust the method with the hyperparameter from the previous example. This should allow for the optimization
     of the model's performance metrics like accuracy, precision, recall, and F1-score.\pagebreak
     Model with Hyperparameters
     \begin{figure}[h]
         \centering
         \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/hyp1.png}
         \label{fig:hyp1}
     \end{figure}
 
     The result display that the model has improved greatly from  its initial predictions.
      Now, the precision has gotten exponentially better in the most unbalanced labels while also improving on the models recall. 
      This means that the models prediction will increase and it's a more oprimize and funcional model\pagebreak
      Results
     \begin{figure}[h]
         \centering
         \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/hyp2.png}
         \label{fig:hp2}
     \end{figure}


\section{Flask}
     The following code saves the model in a json, so that it can be passed to a Flask 
     server with an interface to run the program and make predictions.
     \begin{figure}[h]
         \centering
         \includegraphics[scale=0.4]{/Users/manuelcardenas/Desktop/Latex/AI/images/f1.png}
         \label{fig:f1}
     \end{figure}

\section{Conclution}
In this report, we analyze the Kaggle database to create a data learning and prediction model.
 We implement data balancing methods to be able to manage the data in a more optimal way and for 
 the model to have greater precision. We created 7 different classification methods where we analyzed 
 the results to define which will be the most optimal. Once we determine the best classification method 
 we remove the hyperparameters to improve the performance of the model. Once we achieved this it was just
  a matter of training the model using the optimal number of hyperparameters.\\

Considering the level of precision and recall for each of the labels we can see that the model works well. 
The precision and recall coefficients vary from 70 to 100 depending on the label. This means that data balancing
 along with hyperparameters helped train the model. Assuming that the model was used for data prediction, 
 we could say that it would have good performance since we have to take into account that the labels where I express
  less efficiency are the labels with the least amount of data, so the model could have an accuracy of over 85 percent.

\section{Individual Conclutions}
Héctor Manuel Cárdenas Yáñez\\
In this report I was able to implement the knowledge learned about the subject. The importance of balancing methods 
to improve model performance across all labels. Also implement and analyze different classification methods to determine 
which are the most optimal based on precision and recall. As well as the importance of hyperparameters in solving the challenge. 
Being completely honest during class I did not visualize the importance of these. However, analyzing the before and after results
 of the model, the importance and improvement that it gives to the model is impressive. Once we determine the best classification method.
  I learned to analyze and determine the factors to take into consideration for the analysis of the model with respect to the dataset.\\

Álvaro Morán Errejón\\
Trabajamos durante aproximadamente 5 semanas en este proyecto. Aplicar lo que íbamos aprendiendo en los diferentes
módulos del curso al desafío en el que estábamos trabajando fue una excelente manera de desarrollar nuestras habilidades en
 IA y ciencia de datos. Desde la limpieza y exploración de datos hasta la optimización de hiperparámetros, aprendimos todos 
 los pasos necesarios para construir un modelo sólido. Desde el principio, cuando exploramos la base de datos, estaba claro que
  nuestro mayor desafío sería encontrar una manera eficiente de abordar el desequilibrio de datos que se presentaba. \\

Inicialmente, nuestra idea era simplemente aplicar técnicas de balanceo, como el muestreo o la creación de una función ponderada.
 Sin embargo, al aplicar estas técnicas y evaluar su rendimiento, nos dimos cuenta de que sería mucho más complicado de lo que
  pensábamos. Personalmente, pasé días investigando diferentes técnicas de balanceo, desde las más simples hasta las más avanzadas,
   como ADASYN o SMOTE, que generan ejemplos sintéticos en lugar de duplicar los existentes.\\

Sin embargo, después de probar todas estas técnicas, llegamos a la conclusión de que ninguna era efectiva. Al final del día, 
balancear todos tus datos sin comprender completamente lo que está sucediendo solo cambiará tus datos y tendrá un impacto 
negativo en tus resultados con casos reales. Entonces, decidimos dar un paso atrás y analizar el problema en profundidad con nuestros
 modelos.\\

Al analizar el modelo de Random Forest, que nos brindó los mejores resultados, y centrándonos únicamente en la 
precisión y la exactitud, podríamos haber concluido que teníamos un modelo efectivo. Sin embargo, estos valores altos no 
nos servían de mucho, ya que nuestro recall en ciertas clases era prácticamente 0. Esto se asemeja a desarrollar una red de 
pesca para un lago con 100 peces y tratar de que la red solo atrape peces, en lugar de basura y piedras. Tener una alta precisión 
significaría que la red solo atrapa peces, pero si de los 100 peces en el lago solo atrapamos 2, no es muy útil.\\

Fue en este punto cuando se nos ocurrió usar una extensión del modelo llamada Balanced Random Forest, diseñada precisamente
 para lidiar con clases desequilibradas. Usando este modelo, los resultados nos sorprendieron, ya que fue el primer modelo 
 que nos proporcionó un alto recall. Sin embargo, su precisión era muy baja, y volviendo al ejemplo de la pesca, era como si
  estuviéramos atrapando los 100 peces del lago, pero debido a la baja precisión, también estábamos recogiendo 200 piedras y basura.\\

Decidimos crear un ensamble de los dos modelos para ver si podíamos combinar la alta precisión de uno con el alto recall 
del otro. El ensamble utiliza una técnica en la que los dos modelos se combinan para tomar una decisión conjunta sobre la etiqueta
 de clase de una muestra de entrada.\\

Después de desarrollar este modelo y optimizar los hiperparámetros,
 estábamos satisfechos con los resultados. Creo que lo valioso de este desafío fue comprender que, en la vida real,
  no siempre tendrás datos listos para el modelado, y la mayoría de las veces, lo más tedioso será prepararlos para obtener un
   modelo eficaz. En mi opinión, este desafío fue una gran oportunidad para aprender y me ayudó mucho a comprender cada paso
   necesario para desarrollar un modelo.\\

Desde el primer día, mi objetivo en esta concentración ha sido aprender más sobre la ciencia de datos, ya que en mi trabajo 
llevo ya casi dos años en el área de análisis y exploración, pero me he sentido estancado dado que no he podido realizar tareas 
de modelaje y ciencia de datos. Puedo afirmar con certeza que en estas 5 semanas, a través de este desafío y los módulos del curso,
 he crecido considerablemente y estoy emocionado por seguir aprendiendo y ver qué nos depara el próximo desafío.\\

Isaí Ambrocio\\
El reto me permitió conocer acerca de la minería de datos, esto me ayudó a aprender mucho sobre este campo. 
Comencé entendiendo qué es la minería de datos y en qué consiste. Aprendí que es un proceso de exploración y análisis
 de grandes conjuntos de datos. También, practiqué el análisis exploratorio de datos. 
 Aprendí a visualizar los datos para encontrar patrones y tendencias. También aprendí a interpretar las gráficas
  para obtener información relevante. En la siguiente etapa, comprendí acerca de los balanceos de datos. Aprendí que 
  son técnicas utilizadas para corregir la distribución desigual de los datos. Las técnicas que utilizamos son upsampling,
   weighted loss function y subsampling(está última no la ocupamos pero vimos en que consiste). Finalmente, comprendí 
   sobre los modelos de clasificación. Aprendí que son modelos que se utilizan para predecir la clase de un objeto. 
   Los modelos que aprendí son linear-svm, knn, decision tree, linear discriminant analysis y random forest. \\

Siddhartha López Valenzuela\\
Throughout the completion of this project, I can say that I learned a lot about the different regression and classification models.
 We try together to find the best models, based on the metrics that we consider relevant and important. We ended up with a model that
  I can say is quite good, but with the problem that it is very robust in terms of computational processing, which slows down the
  prediction process. I consider that our delivery of the challenge is very complete, and our results support it; And perhaps there
   is a better model to make more accurate predictions in less time, but with our model, I consider that the problem situation is 
   satisfied.

     

\bibliographystyle{plain}
\bibliography{references}
\end{document}